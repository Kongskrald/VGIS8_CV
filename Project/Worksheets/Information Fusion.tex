


A system that strives to utilise information from two or more different biometric traits in order to obtain one result is a called a multi-modal which is a kind multi-biometric system. Besides the multi-modal approach there are several other approaches which results in information from two or more sources, therefore, methods for fusion of information from different sources into one system for recognition purposes a widely investigated area.  The fusion can happen on different levels. It can happen on as basic a level as the signal level or it can happen on the decision level where the information is classified. In general score-level and feature-level are the most popular fusing techniques. (IRISBOOK). For each of the fusing techniques there are several approaches to how to do the fusing. This can be simply merging data on the lowest level (signals) from different sources to construct a more detailed data set, it can be simply use all of the possible comparisons between obtained datasets and the elements in a gallery and choose the best match, or it can be applying Multiple Classifier Systems. 
Even though recognition based on biometric traits is widely investigated, and research shows that multimodal systems perform better than the uni-modal systems based on the same data, the research in this area is limited and incomplete. Because of the limited access to multimodal datasets, such datasets are often synthetically constructed based on randomly combined iris and face datasets. Only a limited amount of studies on actual utilise a multimodal dataset obtained like that. The named multimodal datasets encountered in literature are the dataset $IV^2$ and the datasets provided for the The Multiple Biometric Grand Challenge. The latter is available on request.  