\chapter{Evaluation}
The evaluation is done in regards to the final networks created and their fulfilment of the requirements. As stated in \autoref{ch:req}, the networks must have a precision of $99\%$ or higher to be comparable to the state of the art networks being used now.

In order to comply with the demands for the input data used for training the systems mentioned in \autoref{ch:req}, the database Warsaw BioBase created by \cite{Trokielewicz2016}, which contains \gls{vl} images of irises obtained with a smart phone is used. The smart phone used was an iPhone 5s with an 8 megapixel camera, which is comparable to the resolution of the front facing cameras in the newest phones on the market. 

The first attempt of obtaining an acceptable accuracy was a unimodal iris classification system using regular machine learning. With this approach it was not possible to reach as high an accuracy as of the state of the art. The best performance achieved was when using a polynomial kernel for the \gls{svm}, which resulted in an accuracy of 98\%. However, the model had a training accuracy of 100\%, thus maybe the model is over fitting. A way to improve this could be training on more data in order to get a more generalised model. Another thing that could be investigated is the polynomial kernel applied, which in this case was defined as a $3^{\text{rd}}$ degree polynomial. However, it is possible that a polynomial of a different degree would map the data to a space where it was better separable by linear hyperplanes. 

Nonetheless, because of this and the objective of the project, deep learning was taken into consideration as a solution. A \gls{cnn} consisting of 14 layers in total was implemented for iris classification. The \gls{cnn} was trained on the same database used for the machine learning method implemented and managed to reach an accuracy of $99.7\%$,\todo{tjek at denne er tilsvarende for hvad vi har opnaaet} ~which satisfies the requirement. The design of this is shown in \autoref{ch:implementation}.

The face recognition \gls{cnn} is based on the VGG16 network and uses the \gls{lfw} database for testing. By using the pre-trained weights from ImageNet trained on 2000 classes it is possible to reach an accuracy of $99.35\%$. The design of this is shown in \autoref{ch:implementation}.