\section{Iris Recognition}
\label{sec:Iris_Recognition_Research}
Modern iris recognition started in with an article by \cite{Daugman1993} discussing the security of using iris for recognition. Here an outline of how to do recognition was laid out and even though the field has been  extensively since, the general methodology is more or less the same. A modern system is typically composed of image acquisition, segmentation and normalization, feature extraction and matching. 

\subsection{Images}
The images aquired are often taken in the \gls{nir} spectrum which is ranging between 700 nm and 900 nm i wavelength. In this band the melanin in the iris, which is the part that gives the iris it's colour e.g. brown or blue, is typically negligible making the unique patterns in the iris very distinct. To acquire usable \gls{nir} images the user has to be in the milimeter range of the \gls{nir} camera.  In the visible light the melanin is seen much more clearly and thus makes is harder to detect the patters. The abbreviation for visible light is not agreed upon in the literature with some examples being \gls{vl} , Visible Spectrum (VIS), and Visible Wavelength (VW). It will be abbreviated \gls{vl} \fxnote{needs to be agreed on} in this report. On the other hand other useful features can be seen in the \gls{vl} that cannot be seen with \gls{nir}. These can include the moles, freckles and conjunctival vasculature which can help in making more accurate recognition systems. To make iris recognitions systems comparable with each other some publicaly available databases are often used. \cite{RifaeeMustafaandAbdallahMohammadandOkosh2017}  give an outline of the some of the free databases that are used in research. A comprehensive table depicting the databases and their contents, sample image and type of noise can be found in \autoref{fig:Iris_database_1} and \autoref{fig:Iris_database_2}. Most of the databases available are \gls{nir} images with CASIA being one of the most used database. For \gls{vl} images UBIRIS in the most common used.  These contain more "real world" data as the images contain more noise in the form of eyelids obstruction, eyelash obstruction, glare, motion blur, out-of-focus or poor focused iris, partial iris and specular reflection \citep{Rattani2017}. The database has also been used in Noisy Iris Challenge Evaluation (NICE) I. The increasing usage of mobile devices also proposes an opportunity to integrate iris recognition as a biometric for verifying the user.  For this purpose a competition, Mobile Iris CHallenge Evaluation (MICHE), is made to compare the state of the art mobile iris. They provide a the MICHE database that can be used which they claim is a better database than UBRIS for mobile systems. The database contains noisy iris images taken with a Galaxy Samsung IV, Iphone5 and Galaxy Tablet II. The noise includes noise from both artificial and natural light sources during acquisition, motion blur, occlusion due to eyelids/glasses/eyelashes/hair/shadows which can naturally occur when a user is trying to unlock a phone using their iris. 

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{figures/Iris_Database_tabel_1.png} 
\caption{A table depicting the contents of free iris image databases.}
\label{fig:Iris_database_1}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{figures/Iris_Database_tabel_2.png} 
\caption{A table depicting the noise present in the databases}
\label{fig:Iris_database_2}
\end{figure}


\subsection{Segmentation}
Segmentation of an iris in iris recognition systems tries to detect the iris and find the pupillary boundary and the limbus boundary as well the eyelids and eyelashes that can cause noise on the image. The boundaries along with other parts of the iris can be seen in \autoref{fig:iris_naming}. The approach used for segmentation depends among other things  on the wavelength of the image; \gls{nir} or \gls{vl}. They both have some common challenges to them. Often the eyelids can over a small part of the iris, making in the limbus bound of the iris to not be circular or elliptical. Eyelashes can also cause a similar disturbance as they also can cover parts of the iris. Poor lighting can also make it extremely difficult to detect the bounds. Specular reflections in the iris can also cause difficulties as they can lie on the iris bounds or close to. Most systems also require a great deal of user cooperation as an off angle iris, motion blur or eye glasses and contact lenses can make it even more difficult to detect the bounds. This can especially be the case for iris recognition in a phone as it cannot be expected of the user know how to take a good iris image. 

\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{figures/iris_naming.png} 
\caption{A close up \gls{nir} image of an iris depicting the different parts of the iris along with their names \citep{Bowyer2016b}}
\label{fig:iris_naming}
\end{figure}

Two commonly observed approaches in \gls{nir} band are Daugmans approach \citep{Daugman1993} , \citep{Saha2017}, \citep{Rattani2017}, \citep{Khan2017}, and Hough Transform \citep{Luhadiya2017}, \citep{Uka2017}. Daugmans approach consists of using a Gaussian filter on the image to attenuate the effect of noise and eliminate undesired weak edges like the boundaries within the iris while keeping the strong edges like iris boundaries and eyelid boundaries. An integro-differential operator is then used as a circular edge detector. It is then used iteratively to find the puppilary boundary and the limbus boundary. Hough Transform  is a histogram based model fitting approach. An edge map of the input map is generated using a gradient-based edge detector. Then a voting procedure is applied on the threshold map to determine the parameters for a contour that best firts a circle. This  operation gives an approximate edge map of the iris boundary. Lastly the segmented iris is often normalized  using  Daugman's rubber sheet model that maps every point in the segmented region from cartesian to polar coordinates. An open source MATLAB implentation based on updated version of the Daugman approach is a commonly used tool\fxnote{Remeber to add a proper citation}. There exist other methods for different circumstances, but these are two most commonly used. They can also be used on \gls{vl} images if the image is converted from RGB to grey scale images \cite{Bowyer2016b} \fxnote{How to properly cite a book where each chapter is written by different people?}. 

\subsection{Feature extraction and classification}
There are multiple ways that the features can be extracted from the segmented iris. The most commonly used in the literature is a 2D Gabor filter which is a linear filter used for edge detection \citep{Daugman1993}. The hamming distance is then used as way to classify the iris. The hamming distance is a measurement of how many bit flips a piece of data need to have to match another piece of data. The bits of the extracted features are then measured against the whole database and the pair with the lowest score is a match. This is called "1-to-N search". As the database gets larger and larger the computation time also grows as it will have to search through the whole database. That's why \cite{Kuehlkamp2016} have suggested using a "1-to-first search" instead to improve the speed of the search. Here a threshold is chosen and as soon as a match has been found below the threshold it will stop the search. Other approaches to the categorisation have been proposed using machine learning. \cite{Khan2017} proposed using \gls{svm}, \gls{knn} and \gls{lda} with respective test accuracies of 97\%, 95.1\%, 94.28\% . In comparions the  commerical systems ranged from 94.57\% to  99.67\% with VeriEye having the lowest and IriCore having the highest accuracy. 

\subsection{Deep Learning}
According to \cite{Zhao2017} research in neural networks with iris recognition is still very new and not much has been done. Some of the work that has been done have used \gls{cnn} and a \gls{dbn}. They claim that the problem with traditional networks are that they are very database specific on not very generalisable. \cite{Zhao2017} created a \gls{fcn} using a loss function they created specifically for iris networks called Extended Triplet Loss (ETL). They claim this network is more generalisable than the previous networks and it shows superior results compared with IrisCode. Another promising approach by \citep{Bazrafkan2017} targets iris segmentation in low-quality consumer images obtained from smartphones is using \gls{spdnn} for generating iris maps from low quality iris images.  In \gls{spdnn} several deep networks are merged into a single model. This way it is possible to include different networks designs and combine their strengths. It was trained by using both \gls{nir} and \gls{vl} images. Extensive noise was also added to the training images in the form of blur and contrast to degrade the high quality images and utilise the databases better. Using the UBRIS database as a comparison with other state of the art segmentation techniques it achieved the highest accuracy with 99.30\%. The lowest of the ones being compared with had an accuracy of 98.10\%.   






%\cite{RifaeeMustafaandAbdallahMohammadandOkosh2017} gives an outline of commercially free databases often used in research.\autoref{fig:Iris_database_1} and \autoref{fig:Iris_database_2} show the different contents of the databases. Most of the databases are \gls{nir} images with CASIA being one most used databases in the literature.  For images in the visible light UBRIS is often used . These contain more "real world" data as the images contain more noise in the form of eyelids obstruction, eyelash obstruction, glare, motion blur, out-of-focus or poor focused iris, partial iris and spec- ular reflection \citep{Rattani2017}. The database has also been used in Noisy Iris Challenge Evaluation (NICE) I. For iris recognition system on mobile platforms the Mobile Iris CHallenge Evaluation (MICHE) database can be used.  The database contains noisy images taken withe Galaxy Samsung IV, Iphone5 and Galaxy Tablet II. The noise includes noise from both artificial and natural light sources during acquisition, motion blur, occlusion due to eyelids/glasses/eyelashes/hair/shadows which can naturally occur when a user is trying to unlock a phone using their iris. 


%. It was also the foundation for IrisCode which is a commercially developed iris recognition algorithm by John Daugman. In 2016 a handbook for iris recognition by \cite{Bowyer2016b} was published giving an outline of the whole process of iris recognition. In general Near Infra-Red (NIR) images of an iris are used but other type of images can also be used.  \cite{Khan2017a} show how to use Daugmans methodology on iris images taken with a smartphone in visible light. They use Daugmans Integro-differential operator to localise the bounds of the iris. Then they suppress the eyelids the eyelids which often cover parts of the iris by using an approach inspired by Masek. Afterwards the image is normalised by using the homogeneous rubber sheet model by Daugman. Then eyelashes are removed from the image and feature extraction is done by using 2D Gabor Waveletts. This approach to extract features in one way or another can be seen in multiple state of the art iris recognition systems and research papers e.g \citep{Luhadiya2017a,Uka2017a,Kuehlkamp2016a}, \cite{Kuehlkamp2016a}. After the features have been extracted they are compared/categorised. Traditionally a "1-to-N search" has been done. Here the Hamming distance of features of the scanned iris are compared to the whole database and it is classified with the iris that has the least distance. \cite{Kuehlkamp2016a} have suggested using a "1-to-first search" instead to improve the speed of the search. Here a threshold is chosen and as soon as a match has been found below the threshold it will stop the search. Other approaches to the categorisation have been proposed using machine learning. \cite{Khan2017a} proposed using Support Vector Machines (SVM), K-Nearest-Neighbours(KNN) and Linear Discriminant Analysis (LDA) with respective test accuracies of 97\%, 95.1\%, 94.28\%. \cite{Zhao2017b} proposed using deep learning to classify. They claim that research in neural networks with iris recognition is still very new and not much has been done. But some of the work that has been done have used Convolutional Neural Networks (CNN) and a Deep Belief Network (DBN). They claim that the problem with traditional networks are that they are very database specific on not very generalisable. \cite{Zhao2017b} created a Fully Convolutional Network (FCN) using a loss function they created specifically for iris networks called Extended Triplet Loss (ETL). They claim this network is more generalisable than the previous networks. 




