\section{Network Fusion}
To be able to combine iris and face verification, a combination of the results of the two networks must be made. Because of time constraints it was not possible to implement this functionality. Instead, the theory of network fusion is presented in this section.

To make this two-stream \gls{cnn} the networks are first training individually and can then be connected using a dense fully connected layers connecting the streams from the two networks. After the fully connected layer a classification is necessary. This can be done using a softmax layer after the dense layer \citep{Eitel2015}. This should in theory increase the accuracy in ID verification in a potential instance where verification is required. The idea of this design is shown in \autoref{fig:net_fusion}.

To be able to reuse as much as possible, the two databases used with the networks separately are also used in the fusion of the networks instead of using a multimodal database as presented in \autoref{cha:Research}. 
This means that a combination of the two databases is necessary as the data have not been collected by the same groups or from the same people. The databases does not have the same amount of classes, therefore the larger database is reduced also reducing the entire amount of usable data.

\subsection{Multimodal Database}
A fusion net should be applied on a multimodal biometric database. Ideally the database used in this project should consist of face and iris images obtained from the same subjects captured with the same camera complying with the requirements set in \autoref{ch:req}. 

However, even though literature suggests that chimeric databases are less adequate than genuine multimodal biometric databases, the multimodal database used during the work with information fusion is synthetically created. This because a few reasons. First of all, as \autoref{sec:multi_modal_data} mentions there are only a limited amount of multimodal biometric databases available containing both iris and face data, and to the extend of the knowledge gain from the research presented in \autoref{sec:info_fuse} there is only one of the databases which is obtained using mobile devices namely the MobBio database. For this database the Asus Transformer Pad TF 300T is used, which has a camera of 8MP, thus comparable to the iPhone 5s used for the caption of the Warsaw-BioBase used for the iris identification methods presented in \autoref{BasicM} and \autoref{sec:cnn_iris_rec} \citep{Sequeira2014}. However, despite several attempts of contacting the responsible for the creation of the database it was not possible to establish communication or gain access to the database. Therefore the available way to obtain a multimodal database with mobile device images is to create it synthetically. Secondly, because the goal is to compare the performance of the fused \gls{cnn}s with the individual \gls{cnn}s on the face and iris data respectively, it is desirable to test on the same data. Therefore a databased was created by combining the \gls{lfw} and the Warsaw-BioBase. 

The database was created by combining iris classes arbitrarily with an face class for as many classes as there were classes available from both the iris and the face dataset. Before combining the datasets the classes with ten or less samples were neglected. The samples inside the new classes was made by combining an arbitrary iris image with an face image for as many samples there are samples available of both the face and iris.\todo{Marike: Shagen, lyder dette rigtigt?} 


