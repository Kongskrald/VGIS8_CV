Automatically generated by Mendeley Desktop 1.17.13
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Zhao2017b,
annote = {Good article describing a lot of the state of the art deep learning approaches being researched.

Keynotes:

Not much work with deep learning has been done in iris recognition.

THey Use a Fully Convolutional Network (FCN) and talk about others who ahve used a Convolutional Neural Network (CNN). They also mention a Deep Belief Net (DBN) that others have used. DeepIrisNet is also mentioned and tested with

THey have created their own loss function optimized for iris recognition called Extended Triplet Loss (ETL)

Their network is generalizable to other databases meaning that it doesn't require finetuing as many others do.

Used ND-IRIS, CASIA Iris, IITD Iris and WVU Non-Ideal Iris databases to test on.},
author = {Zhao, Zijing and Kumar, Ajay},
doi = {10.1109/ICCV.2017.411},
file = {:C$\backslash$:/Users/Shaggy/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao, Kumar - 2017 - Towards More Accurate Iris Recognition Using Deeply Learned Spatially Corresponding Features.pdf:pdf},
isbn = {978-1-5386-1032-9},
journal = {2017 IEEE International Conference on Computer Vision (ICCV)},
pages = {3829--3838},
title = {{Towards More Accurate Iris Recognition Using Deeply Learned Spatially Corresponding Features}},
url = {http://ieeexplore.ieee.org/document/8237673/},
year = {2017}
}
@book{Bowyer2016b,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
annote = {Read only chapter 17 about iris and face fusion. The article gives a nice and clean overview of different multi-biometric systems as well as levels of data abstraction the data fusion can be applied on. 

The work presented performs iris and face fusion using multi-sample, multi instance, and multimodal data. it fuses the multi sample, and multi instance together, by simply finding the best match in the variations. and it fuses the two modalities by rank-level fusion.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Connaughton, Ryan and Bowyer, Kevin W and Flynn, Patrick J},
booktitle = {Handbook of Iris Recognition},
doi = {10.1007/978-1-4471-6784-6},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/Shaggy/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bowyer, Editors - 2016 - Introduction to the Handbook of Iris Recognition.pdf:pdf},
isbn = {978-1-4471-6782-2},
issn = {16130073},
pages = {397--415},
pmid = {25246403},
title = {{Chapter 17 Fusion of Face and Iris Biometrics}},
url = {http://link.springer.com/10.1007/978-1-4471-6784-6},
year = {2016}
}
@article{Neves2017a,
abstract = {{\textcopyright} 2017 IEEE. An error-correcting code (ECC) is a process of adding redundant data to a message, such that it can be recovered by a receiver even if a number of errors are introduced in transmission. Inspired by the principles of ECC, we introduce a method capable of detecting degraded features in biometric signatures by exploiting feature correlation. The main novelty is that, unlike existing biometric cryptosystems, the proposed method works directly on the biometric signature. Our approach performs a redundancy analysis of non-degraded data to build an undirected graphical model (Markov Random Field), whose energy minimization determines the sequence of degraded components of the biometric sample. Experiments carried out in different biometric traits ascertain the improvements attained when disregarding degraded features during the matching phase. Also, we stress that the proposed method is general enough to work in different classification methods, such as CNNs.},
author = {Neves, Joao and Proenca, Hugo},
doi = {10.1109/FG.2017.122},
file = {:C$\backslash$:/Users/Shaggy/Desktop/Iris Articles/Exploiting Data Redundancy for Error Detection in Degraded Biometric Signatures Resulting From in the Wild Environments.pdf:pdf},
isbn = {9781509040230},
journal = {Proceedings - 12th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2017 - 1st International Workshop on Adaptive Shot Learning for Gesture Understanding and Production, ASL4GUP 2017, Biometrics in the Wild, Bwild 2017, Heteroge},
pages = {981--986},
title = {{Exploiting Data Redundancy for Error Detection in Degraded Biometric Signatures Resulting from in the Wild Environments}},
year = {2017}
}
@article{Uka2017a,
annote = {Keynotes:

CASIA (Most used database) and IIT Delhi Iris Database used.

Hough Transofrm algorithm used to detect boundaries},
author = {Uka, Arban and Ro{\c{c}}i, Albana and Ko{\c{c}}, Oktay},
file = {:C$\backslash$:/Users/Shaggy/Desktop/Iris Articles/Improved segmentation algorithm and further optimization for iris recognition.pdf:pdf},
isbn = {9781509038435},
journal = {IEEE EUROCON 2017 -17th International Conference on Smart Technologies},
keywords = {encoding,equal error rate,segmentation},
number = {July},
pages = {6--8},
title = {{Improved Segmentation Algorithm and Further Optimization for Iris Recognition}},
year = {2017}
}
@article{Khan2017a,
annote = {A good article that uses a new database containing smartphone iris images. Theses are taken in visible light. They use Daugmans approach to localize the iris, then they normalize it. They use wavelets on the image to extract the desired featues and then try to classify them using SVM (97{\%}), KNN (95.1{\%}) and LDA (94.28{\%}).

Keynotes:

A different study has used Sparse Reconstruction Classifier with K-means clustering

A different study obtained 99{\%} accuracy using SVM and Hamming Distance

They tried SVM, K-means, Linear Discrimintant in their own study as classifiers.},
author = {Khan, Fahim Faysal and Akif, Ahnaf and Haque, M A},
file = {:C$\backslash$:/Users/Shaggy/Desktop/Iris Articles/Iris recognition using machine learning from smartphone captured images in visible light.pdf:pdf},
isbn = {9781538633748},
pages = {26--28},
title = {{Iris Recognition using Machine Learning from Smartphone Captured Images in Visible Light}},
year = {2017}
}
@article{Daugman1993,
author = {Daugman, J.G.},
doi = {10.1109/34.244676},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {11},
pages = {1148--1161},
title = {{High confidence visual recognition of persons by a test of statistical independence}},
url = {http://ieeexplore.ieee.org/document/244676/},
volume = {15},
year = {1993}
}
@article{Daugman2009a,
abstract = {This chapter explains the iris recognition algorithms and presents results of 9.1 million comparisons among eye images from trials in Britain, the USA, Japan, and Korea. The key to iris recognition is the failure of a test of statistical independence, which involves so many degrees-of-freedom that this test is virtually guaranteed to be passed whenever the phase codes for two different eyes are compared, but to be uniquely failed when any eye's phase code is compared with another version of itself. The test of statistical independence is implemented by the simple Boolean Exclusive-OR operator (XOR) applied to the 2048 bit phase vectors that encode any two iris patterns, masked (AND'ed) by both of their corresponding mask bit vectors to prevent non iris artifacts from influencing iris comparisons. The XOR operator detects disagreement between any corresponding pair of bits, while the AND operator ensures that the compared bits are both deemed to have been uncorrupted by eyelashes, eyelids, specular reflections, or other noise. The norms of the resultant bit vector and of theAND'ed mask vectors are then measured in order to compute a fractional Hamming Distance as the measure of the dissimilarity between any two irises, whose two phase code bit vectors are denoted {\{}. codeA, codeB{\}} and whose mask bit vectors are denoted {\{}. maskA, maskB{\}}. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
annote = {A chapter about how Iris Recognitions works in general. John Daugman is the creator of IrisCode, a 2D Gabor wavelet-based iris recognition algorithm that is the basis of all publicly deployed automatic iris recognition systems and which has registered more than a billion persons worldwide in government ID programs.

Keywords/phrases:
Near Infra Red (NIR) images can be used for iris capturing. 

Gabor wavelets are used for determining the inter and outer edges of an iris.

Often the iris will not be circular because an eyelid will cover it.

Hamming distance is used when comparing two irises.},
author = {Daugman, John},
doi = {10.1016/B978-0-12-374457-9.00025-1},
file = {:C$\backslash$:/Users/Shaggy/Desktop/Iris Articles/The{\_}Essential{\_}Guide{\_}to{\_}Image{\_}Processing{\_}----{\_}(Chapter{\_}25.{\_}How{\_}Iris{\_}Recognition{\_}Works).pdf:pdf},
isbn = {9780123744579},
issn = {10518215},
journal = {The Essential Guide to Image Processing},
pages = {715--739},
pmid = {20810146},
title = {{How Iris Recognition Works}},
year = {2009}
}
@article{Arslan2017a,
abstract = {Biometric systems may be used to create a remote access model on devices, ensure personal data protection, personalize and facilitate the access security. Biometric systems are generally used to increase the security level in addition to the previous authentication methods and they seen as a good solution. Biometry occupies an important place between the areas of daily life of the machine learning. In this study; the techniques, methods, technologies used in biometric systems are researched, machine learning techniques used biometric aplications are investigated for the security perspective, the advantages and disadvantages that these tecniques provide are given. The studies in the literature between 2010-2016 years, used algorithms, technologies, metrics, usage areas, the machine learning techniques used for different biometric systems such as face, palm prints, iris, voice, fingerprint recognition are researched and the studies made are evaluated. The level of security provided by the use of biometric systems by developed using machine learning and disadvantages that arise in the use of these systems are stated in detail in the study. Also, impact on people of biometric methods in terms of ease of use, security and usages areas are examined.},
author = {Arslan, B. and Yorulmaz, E. and Akca, B. and Sagiroglu, S.},
doi = {10.1109/ICMLA.2016.183},
file = {:C$\backslash$:/Users/Shaggy/Desktop/Iris Articles/Security Perspective of Biometric Recognition and Machine Learning Techniques.pdf:pdf},
isbn = {9781509061662},
journal = {Proceedings - 2016 15th IEEE International Conference on Machine Learning and Applications, ICMLA 2016},
keywords = {Biometric,Face,Fingerprint,Iris,Machine learning,Recognition,Security,Teeth,Voice},
pages = {492--497},
title = {{Security perspective of Biometric recognition and machine learning techniques}},
year = {2017}
}
@article{Luhadiya2017a,
annote = {Really good article with a summery of Iris recognition history and approaches in the introduction part.


Keynotes:

Iris database called CASIA with 756 images of 108 people.

SVM used to classify irises.

Elman Recurrent Neural Netowrk used.},
author = {Luhadiya, Ruchi and Khedkar, Anagha},
doi = {10.1109/ICAECCT.2016.7942619},
file = {:C$\backslash$:/Users/Shaggy/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Luhadiya, Khedkar - 2017 - Iris detection for person identification using multiclass SVM.pdf:pdf},
isbn = {9781509036622},
journal = {2016 IEEE International Conference on Advances in Electronics, Communication and Computer Technology, ICAECCT 2016},
keywords = {GLCM,Hough circular transform,Iris,Machine learning,Person identification,SVM},
pages = {387--392},
title = {{Iris detection for person identification using multiclass SVM}},
year = {2017}
}
@article{Proenca2017a,
abstract = {The effectiveness of current iris recognition systems de-pends on the accurate segmentation and parameterisation of the iris boundaries, as failures at this point misalign the coefficients of the biometric signatures. This paper de-scribes IRINA, an algorithm for Iris Recognition that is ro-bust against INAccurately segmented samples, which makes it a good candidate to work in poor-quality data. The pro-cess is based in the concept of " corresponding " patch be-tween pairs of images, that is used to estimate the posterior probabilities that patches regard the same biological region, even in case of segmentation errors and non-linear texture deformations. Such information enables to infer a free-form deformation field (2D registration vectors) between images, whose first and second-order statistics provide effective bio-metric discriminating power. Extensive experiments were carried out in four datasets (CASIA-IrisV3-Lamp, CASIA-IrisV4-Lamp, CASIA-IrisV4-Thousand and WVU) and show that IRINA not only achieves state-of-the-art performance in good quality data, but also handles effectively severe seg-mentation errors and large differences in pupillary dilation / constriction.},
author = {Proenca, Hugo and Neves, Joao C.},
doi = {10.1109/CVPR.2017.714},
file = {:C$\backslash$:/Users/Shaggy/Desktop/Iris Articles/Proenca{\_}IRINA{\_}Iris{\_}Recognition{\_}CVPR{\_}2017{\_}paper.pdf:pdf},
isbn = {978-1-5386-0457-1},
journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
pages = {6747--6756},
title = {{IRINA: Iris Recognition (Even) in Inaccurately Segmented Data}},
url = {http://ieeexplore.ieee.org/document/8100197/},
year = {2017}
}
@article{Saha2017a,
annote = {Not a very good article. but it has some nice references.

Keypoints

It is possible to aquire iris images in multiple way including Near Infrared (NIRD). a simple lense and monochome CCD camera, Adaboost cascade iris detector.

Iris localization is done by Daugman using a 2D Gabor Filter and Fisher Linear Discriminate method.

To help localize the iris despite of eyelashes a 1D rankfilter and histogram filter can be used.},
author = {Saha, Rishmita and Kundu, Mahasweta and Dutta, Madhuparna and Majumder, Rahul and Mukherjee, Debosmita and Pramanik, Sayak and Thakur, Uttam Narendra and Mukherjee, Chiradeep},
file = {:C$\backslash$:/Users/Shaggy/Desktop/Iris Articles/A brief study on evolution of iris recognition system.pdf:pdf},
isbn = {9781538633717},
journal = {Information Technology, Electronics and Mobile Communication Conference (IEMCON), 2017 8th IEEE Annual},
pages = {685--688},
title = {{A Brief Study on Evolution of Iris Recognition System}},
url = {http://ieeexplore.ieee.org.ezproxy.psu.edu.sa/stamp/stamp.jsp?arnumber=8117234},
year = {2017}
}
@article{Hqwhua,
author = {Hqwhu, E and Vndudkdq, Qvndudnrf and Jwx, Dnjxo and Wu, H G X},
file = {::},
keywords = {convolutional neural,deep learning,network,pupil center estimation},
title = {{Deep learning based estimation of the eye pupil center by using image patch classification}}
}
@article{RifaeeMustafaandAbdallahMohammadandOkosh2017a,
author = {Rifaee, Mustafa and Abdallah, Mohammad and Okosh, Basem},
file = {:C$\backslash$:/Users/Shaggy/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rifaee, Mustafa and Abdallah, Mohammad and Okosh - 2017 - A Short Survey for Iris Images Databases.pdf:pdf},
journal = {international journal of multimedia {\&} its applications},
number = {April},
title = {{A Short Survey for Iris Images Databases}},
url = {https://www.researchgate.net/publication/316093004{\_}A{\_}Short{\_}Survey{\_}for{\_}Iris{\_}Images{\_}Databases},
year = {2017}
}
@article{Kuehlkamp2016a,
abstract = {Iris recognition systems are a mature technology that is widely used throughout the world. In identification (as opposed to verification) mode, an iris to be recognized is typically matched against all N enrolled irises. This is the classic "1-to-N search". In order to improve the speed of large-scale identification, a modified "1-to-First" search has been used in some operational systems. A 1-to-First search terminates with the first below-threshold match that is found, whereas a 1-to-N search always finds the best match across all enrollments. We know of no previous studies that evaluate how the accuracy of 1-to-First search differs from that of 1-to-N search. Using a dataset of over 50,000 iris images from 2,800 different irises, we perform experiments to evaluate the relative accuracy of 1-to-First and 1-to-N search. We evaluate how the accuracy difference changes with larger numbers of enrolled irises, and with larger ranges of rotational difference allowed between iris images. We find that False Match error rate for 1-to-First is higher than for 1-to-N, and the the difference grows with larger number of enrolled irises and with larger range of rotation.},
annote = {The way that iris recognition works is that some kind of filter is applied to localize the iris. 2D Gador filter is often cited. Then that iris is checked against the whole database. This is called 1:N. They check the Hamming Distance between of the bits of the data and then choose the lowest ones as a pair. In 1:First search they do the same except there is is a threshold that that is has to be under to be accepted. If it is under that threshold it is accepted and the search is stopped. Two types of error can occour: a False Match (FM) and False Non-Match (FNM). A false match occurs when two samples from different individuals are declared by the system as a match. A false non-match is when two samples from the same individual fail to be considered as a match by the system},
archivePrefix = {arXiv},
arxivId = {1702.01167},
author = {Kuehlkamp, Andrey and Bowyer, Kevin W.},
doi = {10.1109/WACV.2016.7477687},
eprint = {1702.01167},
file = {:C$\backslash$:/Users/Shaggy/Desktop/Iris Articles/An analysis of 1-to-first matching in iris recognition.pdf:pdf},
isbn = {9781509006410},
journal = {2016 IEEE Winter Conference on Applications of Computer Vision, WACV 2016},
title = {{An analysis of 1-to-first matching in iris recognition}},
year = {2016}
}
@article{Ribeiro2017a,
author = {Ribeiro, Eduardo and Uhl, Andreas and Alonso-Fernandez, Fernando and Farrugia, Reuben A.},
doi = {10.23919/EUSIPCO.2017.8081595},
file = {::},
isbn = {978-0-9928626-7-1},
journal = {2017 25th European Signal Processing Conference (EUSIPCO)},
pages = {2176--2180},
title = {{Exploring deep learning image super-resolution for iris recognition}},
url = {http://ieeexplore.ieee.org/document/8081595/},
volume = {2},
year = {2017}
}
@article{Zhang2016a,
author = {Zhang, Man and Zhang, Qi and Sun, Zhenan and Zhou, Shujuan and Ahmed, Nasir Uddin},
doi = {10.1109/BTAS.2016.7791191},
file = {:C$\backslash$:/Users/Shaggy/Desktop/Iris Articles/The BTAS∗Competition on Mobile Iris Recognition.pdf:pdf},
isbn = {9781467397339},
journal = {2016 IEEE 8th International Conference on Biometrics Theory, Applications and Systems, BTAS 2016},
title = {{The BTAS∗Competition on Mobile Iris Recognition}},
year = {2016}
}
